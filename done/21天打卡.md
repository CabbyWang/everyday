```
#21天打卡#Day1
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月13日
学习要点&总结:
数组
1. 数组(Array)是一种线性表数据结构。它由一组连续的内存空间，来存储一组具有相同类型的数据。
2. 随机访问时间复杂度O(1), 插入/删除/查找 时间复杂度O(n), 排好序的数组使用二分查找时间复杂度O(logn)。
3. 警惕数组越界问题。
4. 容器和数组。容器将很多数组操作的细节封装起来。对于业务开发，直接使用容器就足够了，省时省力。
5. 删除时可以先不删除，只是做个标记，等到数组容量快达到阈值时，统一删除，节省数据搬移的成本。
```

```
#21天打卡#Day2
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月14日
学习要点&总结:
链表
1. 数组需要一块连续的内存空间来存储，而链表不需要，链表通过"指针"将一组零散的内存块串联起来使用。
2. 单链表
 每个链表的结点存储数据和记录下一个结点地址的指针(后继指针next)。
 时间复杂度: 
   插入/删除 理论上O(1) 实际O(n) 找到前驱结点还是需要遍历链表，时间复杂度O(n)
   查找 O(n)  因为链表中的数据不是连续的，不能通过首地址和下标来寻址，只能遍历链表
3. 循环链表
 单链表的尾指针指向空地址，循环链表的尾指针指向头结点。
 约瑟夫问题
4. 双向链表
 拥有 前驱指针prev 后继指针next.
 时间复杂度:
   删除给定值的结点 O(n)
   删除给指针指向的结点 O(1)
   插入 O(1)
5. 回文字符串问题
6. 缓存淘汰策略
 FIFO(First In First Out),先进先出策略
 LFU(Least Frequently Used),最少使用策略
 LRU(Least Recently Used),最近最少使用策略
 维护一个有序单链表, 越靠近尾部的结点是越早访问的，当有新数据被访问时，从链表开头顺序遍历链表。如果数据已经存在，则删除，然后插入到链表头部；如果数据不存在，则直接存入到链表头部，如果此时缓存满了则删除尾结点后再插入。
 优化思路，引入散列表记录每个数据的位置，将访问缓存的时间复杂度降到O(1)
```

```
#21天打卡#Day3
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月15日
学习要点&总结:
链表(下)
1. 指针和引用: 存储所指对象的内存地址。
	将某个变量赋值给指针，实际上就是将变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。
2. 警惕指针丢失和内存泄漏
3. 利用哨兵简化实现难度
4. 留意边界条件处理
	a. 链表为空
	b. 链表只包含一个结点
	c. 链表只包含两个结点
	d. 代码逻辑在处理头结点和尾结点时，是否能正常工作
5. 举例画图，辅助思考
	a. 举例法
	b. 画图法
```

```
#21天打卡#Day4
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月16日
学习要点&总结:
栈
1. “操作受限“的线性表。后进者先出，先进者后出。
2. 当某个数据集合只涉及在一端插入和删除数据，并且满足后进后出、先进先出的特性，就应该首选”栈“这种数据结构。
3. 顺序栈: 用数组实现的栈。
   链式栈: 用链表实现的栈。
4. 操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构，用来存储函数调用时的临时变量。
5. 表达式求值
6. 括号匹配
7. 浏览器的前进后退功能
```

```
#21天打卡#Day5
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月17日
学习要点&总结:
队列
1. “操作受限“的线性表。先进者先出，后进者后出。
3. 顺序队列: 用数组实现的队列。
   链式队列: 用链表实现的队列。
4. 循环队列
	解决数据搬移的问题。
	写出没有bug的循环队列的关键是，确定好队空和队满的判定条件。tail=head时队空， (tail+1)/n=head时队满，此时会浪费一个数组的存储空间。
5. 阻塞队列和并发队列
	阻塞队列: 在队列的基础上增加了阻塞操作。队列为空时，从队头取数据会被阻塞；队列已经满时，插入数据会被阻塞。
	并发队列: 线程安全的队列叫做并发队列。 基于数组的循环队列，利用CAS(Compare and Swap)原子操作，可以实现非常高效的并发队列。
6. 考虑使用CAS实现无锁队列，则在入队前，获取tail位置，入队时比较tail是否发生变化，如果否，则允许入队，反之，本次入队失败。出兑则是获取head的位置，进行cas。
```

```
#21天打卡#Day6
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月18日
学习要点&总结:
递归
1. 递归需要满足的三个条件
	1. 一个问题的解可以分解为几个子问题的解
	2. 这个问题与分解之后的子问题，出了数据规模不同，求解思路完全一样
	3. 存在递归终止条件
2. 如何编写递归代码: 写出递推公式，找到终止条件
	写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。
	只要遇到递归，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。
3. 递归代码要警惕堆栈溢出
	在代码中限制递归调用的最大深度
4. 递归代码要警惕重复计算
```

```
#21天打卡#Day7
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月19日
学习要点&总结:
排序(上)
1. 排序算法的执行效率
	1. 最好情况、最坏情况、平均情况时间复杂度
	2. 时间复杂度的系数、常数、低阶
	3. 比较次数和交换(或移动)次数
2. 排序算法的内存消耗(空间复杂度?)
3. 排序算法的稳定性
	稳定的排序算法: 排序前后相等的元素前后顺序没有变化
	不稳定的排序算法
4. 冒泡排序
	遍历n次， 每次将两个元素比较，顺序错误就交换
	1. 原地排序算法
	2. 是稳定的排序算法
	3. 时间复杂度: O(n2)
5. 选择排序
	每次在为排序序列中找到最小元素，存放到已排序序列的尾部
	1. 原地排序算法
	2. 不是稳定的排序算法
	3. 时间复杂度: O(n2)
6. 插入排序
	在未排序序列中取出第一个元素，与已排序序列一个个比较，然后找到相应位置并插入
	1. 原地排序算法
	2. 是稳定的排序算法
	3. 时间复杂度: O(n2)
```

```
#21天打卡#Day8
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月20日
学习要点&总结:
排序(下)
1. 归并排序
	排序一个数组，先将数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组都有序了。
	1. 是稳定的排序算法
	2. 时间复杂度: O(nlogn)
	3. 空间复杂度: O(n)
2. 快速排序
	在数组中选择一个pivot(分区点)，遍历数组将小于pivot的放到左边，大于pivot的放到右边。然后按照同样的操作处理两个分区。
	1. 不是稳定的排序算法
	2. 时间复杂度: O(nlogn) 最坏情况时间复杂度O(n2)
	3. 空间复杂度: O(1)
```

```
#21天打卡#Day9
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月21日
学习要点&总结:
线性排序
1. 桶排序
	1. 将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序取出，组成的序列就是有序的了。
	2. 当桶的个数接近数据个数时，时间复杂度接近O(n)。
	最坏情况下，数据集中在一个桶里，时间复杂度退化为O(nlongn)。
	3. 桶排序比较适合用在外部排序中(数据存储在外部磁盘中，数据量比较大，内存有限，不能全部加载到内存中进行排序)。
2. 计数排序
	1. 计数排序其实是桶排序的一种特殊情况。
	2. 只能用在数据范围不大的场景中。
	3. 计数排序只能给非负整数排序，如果要排序的数据是其他类型，要将其在不改变相对大小的情况下，转化为非负整数。
3. 基数排序
	1. 基数排序对要排序的数据是有要求的，需要可以分割出独立的"位"来比较，而且位之间有递进的关系，如果a数据的高位比b数据大，那剩下的地位就不用比较了。
	2. 每一位的数据范围不能太大。
	3. 每一位要用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到O(n)了。
```

```
#21天打卡#Day10
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月22日
学习要点&总结:
排序优化:如何实现一个通用的、高性能的排序函数。
1. 线性排序算法的时间复杂度比较低，使用场景比较特殊；小规模数据，可以选择O(n2)的算法；如果对大规模数据进行排序，时间复杂度是O(nlogn)的算法更加高效。
2. 如何优化快速排序?
	1. 三数取中法(五数取中、十数取中)
		从首、尾、中间，分别取出一个数，然后对比大小，取中间值作为分区点。
	2. 随机法
		从要排序的区间中，随机选择一个元素作为分区点。
3. 防止堆栈溢出
	1. 限制递归深度
	2. 在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有系统栈大小的限制。
4. c语言的qsort排序函数
	1. 小数据量使用归并排序
	2. 大数据量使用快排
	3. 快排选择分区点的方法是"三数取中法"
	4. 在快排的过程中，当排序的区间元素小于等于4时，退化为插入排序。
```

```
#21天打卡#Day11
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月23日
学习要点&总结:
二分查找(上):如何用最省内存的方式实现快速查找功能
1. 二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为0.
2. O(logn)的惊人查找速度
3. 非递归实现
	1. 循环退出条件
	2. mid的取值
	3. low和high的更新
4. 递归实现
5. 二分查找应用场景的局限性:
	1. 二分查找依赖的是顺序表结构(数组)
	2. 二分查找针对的是有序数据
	3. 数据量太小不适合二分查找
		顺序遍历就足够了
	4. 数据量太大不适合二分查找
		需要"连续"的内存空间
6. 大部分情况下，能用二分查找解决的，都可以使用散列表和二叉树来解决。
```

```
#21天打卡#Day12
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月24日
学习要点&总结:
二分查找(下):如何快速定位IP对应的省份地址？
1. 4种常见的二分查找变形问题
	查找第一个值等于给定值的元素
	查找最后一个值等于给定值的元素
	查找第一个大于等于给定值的元素
	查找最后一个小于等于给定值的元素
2. 如果快速定位IP对应的省份地址
	可以转化为"查找最后一个小雨等于给定值的元素"的问题。找到最后一个起始IP小于等于这个IP的IP区间，然后检查这个IP是否在这个IP区间内，如果在，就取出对应的归属地显示；如果不在，就返回未查找到。
3. 在"近似"查找问题上，二分查找的优势更加明显。散列表和二叉树，比较难以实现。
```

```
#21天打卡#Day13
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月25日
学习要点&总结:
跳表: 为什么Redis一定要用调表来实现有序集合？
1. 每两个结点提取一个结点到上一级，我们把抽出来的那一级叫做索引或索引层。
2. 链表加多级索引的结构，就是跳表。
3. 空间复杂度: O(n)
4. 查找/插入/删除操作时间复杂度都未O(logn)
5. 红黑树、AVL树这样的平衡二叉树是通过左右旋的方式保持左右子树的大小平衡；
	跳表是通过随机函数来维护平衡性。
6. Redis的有序集合通过跳表来实现
	1. 插入、删除、查找时间复杂度和红黑树相同。
	2. 按照区间来查找数据的操作，红黑树的效率没有跳表高。
	3. 跳表的代码实现比红黑树简单。可读性好，不容易出错。
	4. 跳表更加灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。
7. 红黑树比跳表的出现要早一些，很多编程语言的Map类型都是通过红黑树来实现的。
```

```
#21天打卡#Day14
打卡专栏: 数据结构与算法之美
打卡时间: 2020年2月26日
学习要点&总结:
跳表: 散列表(上):Word文档的单词拼写检查功能是如何实现的
1. 散列表其实是数组的一种扩展，由数组演化而来 
	散列表用的是数组支持按照下表随机访问数据的特性
2. key -> hash function -> table
	key通过散列函数计算出一个非负整数作为数组下标，value存储在数组的对应位置上
3. 散列函数设计的基本要求:
	1. 散列函数计算得到的散列值是一个非负整数
	2. 如果 key1 = key2，则 hash(key1) = hash(key2)
	3. 如果 key1 != key2, 则 hash(key1) != hash(key2)
4. 散列冲突
	1. 开放寻址法
		出现散列冲突时，就重新探测一个空闲位置，将其插入
		1. 线性探测 (每次探测步长1)
		2. 二次探测 (每次探测步长变为之前的"二次方")
		3. 双重散列 (使用一组散列函数)
	2. 链表法
```

